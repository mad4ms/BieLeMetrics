{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files in the data/processed directory\n",
    "list_files = glob(\"../data/processed/**/*.csv\", recursive=True)\n",
    "\n",
    "# Load all CSV files into a dictionary of DataFrames\n",
    "dfs = {file: pd.read_csv(file) for file in list_files}\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# extract unique gameday from list_files, where gameday is indicated as **_gd_01_** in the file name\n",
    "gameday = [file.split(\"_gd_\")[1].split(\"_\")[0] for file in list_files]\n",
    "\n",
    "print(f\"Number of unique gameday: {len(set(gameday))}\")\n",
    "print(set(gameday))\n",
    "\n",
    "\n",
    "# Calculate the sorted order based on the count of each event type\n",
    "event_type_order = df[\"event_type\"].value_counts().index\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df)} events\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# print event_type value counts\n",
    "print(df['event_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of rows without sync point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many events have no sync point\n",
    "print(f'Number of events with no sync point: {df[\"event_time_throw\"].isna().sum()}')\n",
    "\n",
    "df_no_sync = df[df[\"event_time_throw\"].isna()]\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df_no_sync, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df_no_sync)} events with no sync point\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column to indicate whether an event has sync or not\n",
    "df[\"sync_status\"] = df[\"event_time_throw\"].notna().map({True: 'With Sync', False: 'Without Sync'})\n",
    "\n",
    "# Define the order of event types if needed\n",
    "# event_type_order = ['event_type_1', 'event_type_2', ...]  # Adjust this to your event type order\n",
    "\n",
    "# Plot the stacked count of event types for events with and without sync\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a stacked countplot based on sync status\n",
    "sns.countplot(data=df, x=\"name_team_home\", hue=\"sync_status\", palette=\"Set2\", dodge=False)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Event Type Distribution (Stacked by Sync Status)\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Add grid for both axes\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "\n",
    "# Rotate x-ticks for readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the events with sync points\n",
    "df_sync = df.dropna(subset=[\"event_time_throw\"])\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df_sync, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df_sync)} events with sync point\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution over teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many matches have the teams played at home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by home team and count the number of matches for each team\n",
    "df_grouped = df.groupby(\"name_team_home\")[\"match_id\"].nunique().reset_index(name=\"count\")\n",
    "\n",
    "# Sort by the number of home matches for better visual clarity\n",
    "df_grouped = df_grouped.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Plot the bar chart of home matches per team\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_grouped, x=\"name_team_home\", y=\"count\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Number of Home Matches by Team\")\n",
    "plt.xlabel(\"Team\")\n",
    "plt.ylabel(\"Number of Home Matches\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", axis='y', alpha=0.2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the teams by overall count of events\n",
    "team_order = df_sync['name_team_home'].value_counts().index\n",
    "\n",
    "# Plot the stacked histogram of event_type for each team, sorted by team count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df_sync, x=\"name_team_home\", hue=\"event_type\", bins=50, multiple=\"stack\")\n",
    "\n",
    "# Calculate the average number of events per team\n",
    "average_event_count = df_sync.groupby('name_team_home').size().mean()\n",
    "\n",
    "# Add a vertical line representing the average number of events per team\n",
    "plt.axhline(average_event_count, color='red', linestyle='--', label=f'Average: {average_event_count:.1f}')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f\"Event Type Distribution for {len(df_sync)} events with sync point\")\n",
    "plt.xlabel(\"Team\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", alpha=0.2)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add legend for the average line\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"distance_player_to_goal\",  # distance between player and the goal\n",
    "    \"distance_player_to_goalkeeper\",  # distance between player and goalkeeper\n",
    "    \"distance_goalkeeper_to_goal\",  # distance between goalkeeper and goal\n",
    "    \"angle_player_to_goal\",  # angle of the ball relative to the goal\n",
    "    # \"angle_ball_to_goal\",\n",
    "    # \"speed_ball\",  # speed of the ball when thrown\n",
    "    \"speed_player\",  # speed of the player\n",
    "    \"distance_player_to_nearst_opponent\",  # distance to the nearest defender\n",
    "    \"distance_player_to_nearest_teammate\",  # number of defenders close to the player\n",
    "    \"num_opponents_between_player_and_goal\",  # number of defenders between player and goal\n",
    "    \"num_opponents_close_to_player\",  # number of defenders close to the player\n",
    "    \"efficiency_shots_team\",  # efficiency of the team in scoring goals\n",
    "    \"efficiency_shots_player\",  # efficiency of the player in scoring goals\n",
    "    \"efficiency_goalkeeper\",  # efficiency of the goalkeeper in saving goals\n",
    "    # \"home_advantage\",  # home advantage\n",
    "]\n",
    "\n",
    "target_column = \"event_type\"  # target column to predict\n",
    "\n",
    "\n",
    "df_features = df[features].copy()\n",
    "\n",
    "df_features[\"target\"] = df[\"event_type\"].apply(\n",
    "    lambda x: 1 if x == \"score_change\" else 0\n",
    ")\n",
    "\n",
    "df_features[\"target_as_string\"] = df[\"event_type\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_features.shape[0])\n",
    "# how many nans\n",
    "print(f'Before dropping NaNs\\n')\n",
    "print(f'Total number of rows: {df_features.shape[0]}\\n')\n",
    "print(df_features.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hist of features\n",
    "df_features.hist(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot NaN histogram\n",
    "# Count the number of NaN values per feature\n",
    "nan_counts = df_features.isnull().sum()\n",
    "\n",
    "# Sort the NaN counts in descending order (optional for better visualization)\n",
    "nan_counts = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# Plot the NaN counts as a bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=nan_counts.index, y=nan_counts.values, palette='viridis')\n",
    "\n",
    "# Rotate the x labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Features\", fontsize=12)\n",
    "plt.ylabel(\"Number of NaN Values\", fontsize=12)\n",
    "plt.title(\"Number of NaN Values per Feature\", fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot nans grouped by name_team_home\n",
    "nan_counts = df_features.isnull().sum()\n",
    "nan_counts = nan_counts[nan_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# Group by home team and count the number of NaN values for each team\n",
    "df_grouped = df_features.groupby(\"name_team_home\")[nan_counts.index].sum()\n",
    "\n",
    "# Sort by the total number of NaN values for better visual clarity\n",
    "df_grouped = df_grouped.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# Plot the bar chart of NaN values per team\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_grouped.reset_index(), x=\"name_team_home\", y=0)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Number of NaN Values by Team\")\n",
    "plt.xlabel(\"Team\")\n",
    "plt.ylabel(\"Number of NaN Values\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unrealistic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target column because we want to see if it correlates with the features\n",
    "# target is 1 if the event is a event_type is \"score_change\", 0 otherwise\n",
    "\n",
    "# Correlation matrix for df_features but without the target_as_string column\n",
    "corr = df_features.drop(columns=[\"target_as_string\"]).corr()\n",
    "# Correlation matrix\n",
    "# corr = df_features.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=1,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print most correlated features\n",
    "print(corr[\"target\"].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Importance with a Tree-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Define the feature columns (excluding the target)\n",
    "feature_columns = df_features.drop(\"target\", axis=1).drop(\"target_as_string\", axis=1).columns\n",
    "# Train a Random Forest model to check feature importance\n",
    "X = df_features[feature_columns]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances = pd.Series(model.feature_importances_, index=feature_columns)\n",
    "\n",
    "# Sort and plot feature importances\n",
    "feature_importances.sort_values(ascending=False).plot(kind=\"barh\", figsize=(12, 6))\n",
    "plt.title(\"Feature Importances from Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is there mutual information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute the mutual information between each feature and the target\n",
    "mi = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "mi_series = pd.Series(mi, index=feature_columns)\n",
    "mi_series.sort_values(ascending=False).plot(kind=\"barh\", figsize=(12, 6))\n",
    "plt.title(\"Mutual Information Scores\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold (Detecting Low-Variance Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Apply a variance threshold to remove features with low variance\n",
    "selector = VarianceThreshold(threshold=0.1)  # Choose an appropriate threshold\n",
    "selector.fit(X)\n",
    "\n",
    "# Get the remaining features\n",
    "remaining_features = X.columns[selector.get_support()]\n",
    "print(f\"Features retained after variance threshold: {list(remaining_features)}\")\n",
    "# print features that were dropped\n",
    "print(f\"Features dropped after variance threshold: {list(X.columns[~selector.get_support()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = feature_columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(feature_columns))]\n",
    "\n",
    "# Print VIF data\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Distributions and Target Separation (Boxplots and KDEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA and plot the first two components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y, cmap='viridis')\n",
    "plt.title(\"PCA of Features\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the features and target column\n",
    "X = df_features[features]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply RandomUndersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = 1\n",
    "# rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "# X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "# # print distribution of target column\n",
    "# print(y_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = X\n",
    "y_res = y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and algorithms for automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = \"../data/ml_stuff/automl_8\"\n",
    "\n",
    "algorithms=[\n",
    "    \"Xgboost\",\n",
    "    \"CatBoost\",\n",
    "    \"Random Forest\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl = AutoML(\n",
    "#     results_path=path_out,\n",
    "#     algorithms=[\n",
    "#         \"Xgboost\",\n",
    "#         \"CatBoost\",\n",
    "#         \"Random Forest\",\n",
    "#     ],\n",
    "#     total_time_limit=5 * 60,\n",
    "#     # n_jobs=6,\n",
    "#     explain_level=2,\n",
    "#     mode=\"Explain\",\n",
    "#     random_state=42,\n",
    "    \n",
    "# )\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path=path_out,\n",
    "    algorithms=[\n",
    "        \"Xgboost\",\n",
    "        \"CatBoost\",\n",
    "        \"Random Forest\",\n",
    "    ],\n",
    "    total_time_limit=5 * 60,\n",
    "    # n_jobs=6,\n",
    "    explain_level=2,\n",
    "    mode=\"Explain\",\n",
    "    random_state=42,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target values\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "\n",
    "# plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now apply model on complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply model on complete dataframe and insert column \"xG\"\n",
    "X = df_features[features]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = automl.predict(X)\n",
    "# get proba\n",
    "y_pred = automl.predict_proba(X)[:, 1]\n",
    "\n",
    "# insert column \"xG\" into df_features\n",
    "df_features[\"xG\"] = y_pred\n",
    "\n",
    "# print some xG\n",
    "print(df_features[\"xG\"].value_counts())\n",
    "\n",
    "# insert xG of df_features into df\n",
    "df[\"xG\"] = df_features[\"xG\"]\n",
    "# and target\n",
    "df[\"target\"] = df_features[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot positions and xG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure and axis for the histogram\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the histogram with stacking based on target (score change)\n",
    "sns.histplot(data=df, x=\"xG\", bins=50, hue=\"target\", multiple=\"stack\", palette=\"Set1\", stat=\"count\", ax=ax1)\n",
    "\n",
    "# Set labels and grid for the first y-axis (counts)\n",
    "ax1.set_title(\"xG Distribution (Stacked by Score Change) with Density Lines\")\n",
    "ax1.set_xlabel(\"xG\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.grid(True, \"both\", alpha=0.2)\n",
    "\n",
    "# Create a second y-axis for the density\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Add density lines for both score change == 0 and score change == 1 on the second y-axis\n",
    "sns.kdeplot(data=df[df[\"target\"] == 0], x=\"xG\", color=\"red\", label=\"Density (No Score Change)\", ax=ax2, lw=2)\n",
    "sns.kdeplot(data=df[df[\"target\"] == 1], x=\"xG\", color=\"blue\", label=\"Density (Score Change)\", ax=ax2, lw=2)\n",
    "\n",
    "# Set label for the second y-axis (density)\n",
    "ax2.set_ylabel(\"Density\")\n",
    "\n",
    "# Show legends for the density lines\n",
    "ax2.legend(loc=\"upper left\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.copy()\n",
    "# group by name_team_home and calculate mean y position\n",
    "\n",
    "# plot positions and xG\n",
    "plt.figure(figsize=(10, 6))\n",
    "# assets\\handballfeld.png\n",
    "img = plt.imread(\"../assets/handballfeld.png\")\n",
    "plt.imshow(img, extent=[0, 40, 0, 20])\n",
    "plt.scatter(df[\"pos_x_player\"], df[\"pos_y_player\"], c=df[\"xG\"], cmap=\"coolwarm\")\n",
    "plt.colorbar()\n",
    "plt.title(\"xG of Throws\")\n",
    "plt.xlabel(\"x-coordinate\")\n",
    "plt.ylabel(\"y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# display\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by player and calculate the sum of xG and goals, and count the number of throws\n",
    "df_grouped = df.groupby(\"name_player\")[[\"xG\", \"target\"]].agg(['sum', 'count']).reset_index()\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "df_grouped.columns = [\"name_player\", \"xG_sum\", \"goal_sum\", \"xG_count\", \"goal_count\"]\n",
    "\n",
    "# Normalize the xG and goals by dividing by the number of throws (using the count for xG or target)\n",
    "# df_grouped[\"xG_normalized\"] = df_grouped[\"xG_sum\"] / len(df_grouped)\n",
    "# df_grouped[\"goal_normalized\"] = df_grouped[\"goal_sum\"] / len(df_grouped)\n",
    "\n",
    "# sort by xG sum\n",
    "df_grouped = df_grouped.sort_values(by=\"goal_count\", ascending=True)\n",
    "# drop players with less than 10 throws\n",
    "df_grouped = df_grouped[df_grouped[\"goal_count\"] > 30]\n",
    "\n",
    "# Display the dataframe to check the results\n",
    "display(df_grouped.head())\n",
    "\n",
    "# Plot xG sum vs. goal sum (both normalized)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(df_grouped[\"xG_sum\"], df_grouped[\"goal_sum\"], color='blue', alpha=0.7)\n",
    "plt.title(\"Normalized xG Sum vs Normalized Goal Sum\")\n",
    "plt.xlabel(\"Normalized xG\")\n",
    "plt.ylabel(\"Normalized Goals\")\n",
    "# make axis equal\n",
    "# plt.axis('equal')\n",
    "# bot start at 0\n",
    "plt.xlim(0, 70)\n",
    "plt.ylim(0.0, 70)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print information about the xG, which teams are the best atm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate xG and actual goals (target) for each team\n",
    "df_team_stats = df.groupby(\"name_team_home\").agg(\n",
    "    total_xG=(\"xG\", \"sum\"),\n",
    "    total_goals=(\"target\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "# Melt the DataFrame to a long format for easier plotting\n",
    "df_melted = pd.melt(df_team_stats, id_vars=[\"name_team_home\"], value_vars=[\"total_xG\", \"total_goals\"],\n",
    "                    var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# Sort the teams by xG or total goals\n",
    "df_team_stats = df_team_stats.sort_values(by=\"total_xG\", ascending=False)\n",
    "\n",
    "# Plot the xG and actual goals side by side for each team\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_melted, x=\"name_team_home\", y=\"Value\", hue=\"Metric\", palette=\"Blues_d\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Total xG and Actual Goals by Home Team\", fontsize=16)\n",
    "plt.xlabel(\"Team\", fontsize=12)\n",
    "plt.ylabel(\"Total Value\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add gridlines for the y-axis\n",
    "plt.grid(True, which=\"both\", axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'num_events' represents the number of matches or events for each team\n",
    "# df_team_stats[\"num_events\"] = df[\"name_team_home\"].value_counts()\n",
    "\n",
    "# display(df_team_stats)\n",
    "# # transform df_team_stats[\"num_events\"] to int\n",
    "# df_team_stats[\"num_events\"] = df_team_stats[\"num_events\"].astype(int)\n",
    "\n",
    "# df_team_stats[\"xG_per_event\"] = df_team_stats[\"total_xG\"] / df_team_stats[\"num_events\"]\n",
    "# df_team_stats[\"goals_per_event\"] = df_team_stats[\"total_goals\"] / df_team_stats[\"num_events\"]\n",
    "\n",
    "# # Melt the DataFrame to a long format for easier plotting\n",
    "# df_melted = pd.melt(df_team_stats, id_vars=[\"name_team_home\"], value_vars=[\"xG_per_event\", \"goals_per_event\"],\n",
    "#                     var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# # Plot normalized xG vs normalized goals\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(data=df_team_stats, x=\"xG_per_event\", y=\"goals_per_event\", hue=\"name_team_home\", s=100)\n",
    "\n",
    "# # Add title and labels\n",
    "# plt.title(\"Normalized xG vs Actual Goals by Home Team (Per Event)\", fontsize=16)\n",
    "# plt.xlabel(\"Normalized xG (Per Event)\", fontsize=12)\n",
    "# plt.ylabel(\"Normalized Goals (Per Event)\", fontsize=12)\n",
    "\n",
    "# # Add 1:1 line\n",
    "# plt.plot([0, df_team_stats[\"xG_per_event\"].max()], [0, df_team_stats[\"goals_per_event\"].max()], color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# # Adjust axis limits based on normalized values\n",
    "# plt.xlim(0, df_team_stats[\"xG_per_event\"].max() + 0.1)\n",
    "# plt.ylim(0, df_team_stats[\"goals_per_event\"].max() + 0.1)\n",
    "\n",
    "# # Add gridlines\n",
    "# plt.grid(True, which=\"both\", alpha=0.3)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot xG vs actual goals\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=df_team_stats, x=\"total_xG\", y=\"total_goals\", hue=\"name_team_home\", s=100)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Total xG vs Actual Goals by Home Team\", fontsize=16)\n",
    "plt.xlabel(\"Total xG\", fontsize=12)\n",
    "plt.ylabel(\"Total Goals\", fontsize=12)\n",
    "\n",
    "# make axis equal and add 1:1 line\n",
    "# plt.axis(\"equal\")\n",
    "plt.plot([0, 300], [0, 300], color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# limits to 0-300\n",
    "plt.xlim(150, 300)\n",
    "plt.ylim(150, 300)\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_github_bielemetrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
