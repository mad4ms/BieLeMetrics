{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files in the data/processed directory\n",
    "list_files = glob(\"../data/processed/**/*.csv\", recursive=True)\n",
    "\n",
    "# Load all CSV files into a dictionary of DataFrames\n",
    "dfs = {file: pd.read_csv(file) for file in list_files}\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# Calculate the sorted order based on the count of each event type\n",
    "event_type_order = df[\"event_type\"].value_counts().index\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df)} events\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# print event_type value counts\n",
    "print(df['event_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of rows without sync point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many events have no sync point\n",
    "print(f'Number of events with no sync point: {df[\"event_time_throw\"].isna().sum()}')\n",
    "\n",
    "df_no_sync = df[df[\"event_time_throw\"].isna()]\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df_no_sync, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df_no_sync)} events with no sync point\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event_type value counts\n",
    "print(df_no_sync['event_type'].value_counts())\n",
    "\n",
    "# is this team related? Histogram of name_team_home\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df_no_sync, x=\"name_team_home\")  # Sort by count\n",
    "plt.title(f\"Team Home Distribution for {len(df_no_sync)} events with no sync point\")\n",
    "plt.xlabel(\"Team Home\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the events with sync points\n",
    "df_sync = df.dropna(subset=[\"event_time_throw\"])\n",
    "\n",
    "# Plot the sorted histogram of event_type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df_sync, x=\"event_type\", order=event_type_order)  # Sort by count\n",
    "plt.title(f\"Event Type Distribution for {len(df_sync)} events with sync point\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "# grid, both axis\n",
    "plt.grid(True, \"both\", alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution over teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many matches have the teams played at home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by home team and count the number of matches for each team\n",
    "df_grouped = df.groupby(\"name_team_home\")[\"match_id\"].nunique().reset_index(name=\"count\")\n",
    "\n",
    "# Sort by the number of home matches for better visual clarity\n",
    "df_grouped = df_grouped.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Plot the bar chart of home matches per team\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_grouped, x=\"name_team_home\", y=\"count\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Number of Home Matches by Team\")\n",
    "plt.xlabel(\"Team\")\n",
    "plt.ylabel(\"Number of Home Matches\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", axis='y', alpha=0.2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the teams by overall count of events\n",
    "team_order = df_sync['name_team_home'].value_counts().index\n",
    "\n",
    "# Plot the stacked histogram of event_type for each team, sorted by team count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df_sync, x=\"name_team_home\", hue=\"event_type\", bins=50, multiple=\"stack\")\n",
    "\n",
    "# Calculate the average number of events per team\n",
    "average_event_count = df_sync.groupby('name_team_home').size().mean()\n",
    "\n",
    "# Add a vertical line representing the average number of events per team\n",
    "plt.axhline(average_event_count, color='red', linestyle='--', label=f'Average: {average_event_count:.1f}')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f\"Event Type Distribution for {len(df_sync)} events with sync point\")\n",
    "plt.xlabel(\"Team\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", alpha=0.2)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add legend for the average line\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"distance_player_to_goal\",  # distance between player and the goal\n",
    "    \"distance_player_to_goalkeeper\",  # distance between player and goalkeeper\n",
    "    \"distance_goalkeeper_to_goal\",  # distance between goalkeeper and goal\n",
    "    \"angle_player_to_goal\",  # angle of the ball relative to the goal\n",
    "    # \"angle_ball_to_goal\",\n",
    "    # \"speed_ball\",  # speed of the ball when thrown\n",
    "    \"speed_player\",  # speed of the player\n",
    "    \"distance_player_to_nearst_opponent\",  # distance to the nearest defender\n",
    "    \"distance_player_to_nearest_teammate\",  # number of defenders close to the player\n",
    "    # \"num_opponents_between_player_and_goal\",  # number of defenders between player and goal\n",
    "    \"num_opponents_close_to_player\",  # number of defenders close to the player\n",
    "    \"efficiency_shots_team\",  # efficiency of the team in scoring goals\n",
    "    \"efficiency_shots_player\",  # efficiency of the player in scoring goals\n",
    "    \"efficiency_goalkeeper\",  # efficiency of the goalkeeper in saving goals\n",
    "    # \"home_advantage\",  # home advantage\n",
    "]\n",
    "\n",
    "target_column = \"event_type\"  # target column to predict\n",
    "\n",
    "\n",
    "df_features = df[features].copy()\n",
    "\n",
    "df_features[\"target\"] = df[\"event_type\"].apply(\n",
    "    lambda x: 1 if x == \"score_change\" else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_features.shape[0])\n",
    "# how many nans\n",
    "print(f'Before dropping NaNs\\n')\n",
    "print(f'Total number of rows: {df_features.shape[0]}\\n')\n",
    "print(df_features.isnull().sum())\n",
    "# drop nans\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "print(\"\\n\\nAfter dropping NaNs\")\n",
    "# how many nans\n",
    "print(df_features.isnull().sum())\n",
    "print(f'Total number of rows: {df_features.shape[0]}\\n')\n",
    "\n",
    "# length of df[df[\"distance_player_goal\"] < 20]\n",
    "print(df_features[df_features[\"distance_player_to_goal\"] < 20].shape[0])\n",
    "print(df_features[df_features[\"distance_player_to_goal\"] >= 20].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target column because we want to see if it correlates with the features\n",
    "# target is 1 if the event is a event_type is \"score_change\", 0 otherwise\n",
    "\n",
    "\n",
    "# Correlation matrix\n",
    "corr = df_features.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=1,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print most correlated features\n",
    "print(corr[\"target\"].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Importance with a Tree-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Define the feature columns (excluding the target)\n",
    "feature_columns = df_features.drop(\"target\", axis=1).columns\n",
    "\n",
    "# Train a Random Forest model to check feature importance\n",
    "X = df_features[feature_columns]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances = pd.Series(model.feature_importances_, index=feature_columns)\n",
    "\n",
    "# Sort and plot feature importances\n",
    "feature_importances.sort_values(ascending=False).plot(kind=\"barh\", figsize=(12, 6))\n",
    "plt.title(\"Feature Importances from Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is there mutual information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute the mutual information between each feature and the target\n",
    "mi = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "mi_series = pd.Series(mi, index=feature_columns)\n",
    "mi_series.sort_values(ascending=False).plot(kind=\"barh\", figsize=(12, 6))\n",
    "plt.title(\"Mutual Information Scores\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold (Detecting Low-Variance Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Apply a variance threshold to remove features with low variance\n",
    "selector = VarianceThreshold(threshold=0.1)  # Choose an appropriate threshold\n",
    "selector.fit(X)\n",
    "\n",
    "# Get the remaining features\n",
    "remaining_features = X.columns[selector.get_support()]\n",
    "print(f\"Features retained after variance threshold: {list(remaining_features)}\")\n",
    "# print features that were dropped\n",
    "print(f\"Features dropped after variance threshold: {list(X.columns[~selector.get_support()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = feature_columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(feature_columns))]\n",
    "\n",
    "# Print VIF data\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Distributions and Target Separation (Boxplots and KDEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA and plot the first two components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y, cmap='viridis')\n",
    "plt.title(\"PCA of Features\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the features and target column\n",
    "X = df_features[features]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply RandomUndersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy = 1\n",
    "rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "# print distribution of target column\n",
    "print(y_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and algorithms for automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = \"../data/ml_stuff/automl_3\"\n",
    "\n",
    "algorithms=[\n",
    "    \"Xgboost\",\n",
    "    \"CatBoost\",\n",
    "    \"Random Forest\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(\n",
    "    results_path=path_out,\n",
    "    algorithms=[\n",
    "        \"Xgboost\",\n",
    "        \"CatBoost\",\n",
    "        \"Random Forest\",\n",
    "    ],\n",
    "    total_time_limit=5 * 60,\n",
    "    # n_jobs=6,\n",
    "    explain_level=2,\n",
    "    mode=\"Explain\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target values\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now apply model on complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply model on complete dataframe and insert column \"xG\"\n",
    "X = df_features[features]\n",
    "y = df_features[\"target\"]\n",
    "\n",
    "# Predict the target values\n",
    "y_pred = automl.predict(X)\n",
    "# get proba\n",
    "y_pred = automl.predict_proba(X)[:, 1]\n",
    "\n",
    "# insert column \"xG\" into df_features\n",
    "df_features[\"xG\"] = y_pred\n",
    "\n",
    "# print some xG\n",
    "print(df_features[\"xG\"].value_counts())\n",
    "\n",
    "# insert xG of df_features into df\n",
    "df[\"xG\"] = df_features[\"xG\"]\n",
    "# and target\n",
    "df[\"target\"] = df_features[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print information about the xG, which teams are the best atm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate xG and actual goals (target) for each team\n",
    "df_team_stats = df.groupby(\"name_team_home\").agg(\n",
    "    total_xG=(\"xG\", \"sum\"),\n",
    "    total_goals=(\"target\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "# Melt the DataFrame to a long format for easier plotting\n",
    "df_melted = pd.melt(df_team_stats, id_vars=[\"name_team_home\"], value_vars=[\"total_xG\", \"total_goals\"],\n",
    "                    var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# Sort the teams by xG or total goals\n",
    "df_team_stats = df_team_stats.sort_values(by=\"total_xG\", ascending=False)\n",
    "\n",
    "# Plot the xG and actual goals side by side for each team\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_melted, x=\"name_team_home\", y=\"Value\", hue=\"Metric\", palette=\"Blues_d\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Total xG and Actual Goals by Home Team\", fontsize=16)\n",
    "plt.xlabel(\"Team\", fontsize=12)\n",
    "plt.ylabel(\"Total Value\", fontsize=12)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add gridlines for the y-axis\n",
    "plt.grid(True, which=\"both\", axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_github_bielemetrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
